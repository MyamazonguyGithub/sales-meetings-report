{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "## Install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas statsmodels numpy scikit-learn scipy tranformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import linregress, pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.get_transcript import get_transcript_dfs\n",
    "\n",
    "# Replace the meeting_id with the meeting_id of the meeting you want to analyze\n",
    "transcript_dfs = get_transcript_dfs('jKr7GjngjZdqWWiW')\n",
    "sentences_df = transcript_dfs['sentences_df']\n",
    "meeting_df = transcript_dfs['meeting_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up the Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from transformers import logging as transformers_logging\n",
    "\n",
    "# Suppress only the specific warning from transformers\n",
    "transformers_logging.set_verbosity_error()\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment-latest')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment-latest')\n",
    "\n",
    "def calculate_sentiment_classification_scores(sentence: str) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the sentiment classification scores of a sentence.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The sentence to calculate the sentiment classification for.\n",
    "\n",
    "    Returns:\n",
    "        dict: The sentiment classification scores of the sentence.\n",
    "    \"\"\"\n",
    "    # Get probabilities for each label\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    labels = model.config.id2label\n",
    "\n",
    "    # Map probabilities to labels\n",
    "    result = {labels[i]: prob.item() for i, prob in enumerate(probs[0])}\n",
    "\n",
    "    # Ensure all expected keys are present\n",
    "    for key in ['negative', 'neutral', 'positive']:\n",
    "        if key not in result:\n",
    "            result[key] = 0.0\n",
    "    return result\n",
    "\n",
    "def set_overall_sentiment_score(meeting_df: pd.DataFrame, sentences_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the sentiment score of a conversation based on the sentiment of the sentences in the conversation.\n",
    "\n",
    "    Args:\n",
    "        sentences_df (pd.DataFrame): The DataFrame containing the sentences to calculate the sentiment score for.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame containing the sentiment scores of the sentences.\n",
    "    \"\"\"\n",
    "    # Calculate the sentiment classification scores of each sentence and expand the dictionary into separate columns\n",
    "    sentiment_scores_df = sentences_df['text'].apply(calculate_sentiment_classification_scores).apply(pd.Series)\n",
    "    sentiment_scores_df = sentiment_scores_df.add_prefix('sentiment_')\n",
    "    for col in sentiment_scores_df.columns:\n",
    "        sentences_df[col] = sentiment_scores_df[col]\n",
    "    sentences_df['sentiment_score'] = -1 * sentences_df['sentiment_negative'] + 0 * sentences_df['sentiment_neutral'] + 1 * sentences_df['sentiment_positive']\n",
    "\n",
    "    sentences_df['duration'] = sentences_df['end_time'] - sentences_df['start_time']\n",
    "    sentences_df['cumulative_duration'] = sentences_df['duration'].cumsum()\n",
    "\n",
    "    sentences_df['weighted_sentiment_score'] = sentences_df['sentiment_score'] * sentences_df['duration']\n",
    "    overall_sentiment_score = sentences_df['weighted_sentiment_score'].sum() / sentences_df['duration'].sum() if sentences_df['duration'].sum() != 0 else 0\n",
    "\n",
    "    meeting_df['sentiment_score'] = overall_sentiment_score\n",
    "\n",
    "    return meeting_df, sentences_df\n",
    "\n",
    "\n",
    "meeting_df, sentences_df = set_overall_sentiment_score(meeting_df, sentences_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotional Intensity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", top_k=None)\n",
    "excluded_emotions = ['neutral']\n",
    "emotions = [emotion for emotion in classifier.model.config.id2label.values() if emotion not in excluded_emotions]\n",
    "\n",
    "\n",
    "def calculate_emotional_scores(sentence: str) -> float:\n",
    "\t\"\"\"\n",
    "\tCalculate the emotional scores of a conversation based on the emotional scores of the sentences in the conversation.\n",
    "\n",
    "\tArgs:\n",
    "\t\tsentence (str): The sentence to calculate the emotional scores for.\n",
    "\n",
    "\tReturns:\n",
    "\t\tfloat: The emotional scores of the conversation.\n",
    "\t\"\"\"\n",
    "\n",
    "\tclassifications = classifier(sentence)[0]\n",
    "\tclassifications = {\n",
    "\t\tclassification['label']: classification['score']\n",
    "\t\tfor classification in classifications\n",
    "\t}\n",
    "\n",
    "\treturn classifications\n",
    "\n",
    "\n",
    "def calculate_emotional_intensity_score(sentence: str) -> float:\n",
    "\t\"\"\"\n",
    "\tCalculate the emotional intensity score of a conversation based on the emotional intensity of the sentences in the conversation.\n",
    "\n",
    "\tArgs:\n",
    "\t\tsentence (str): The sentence to calculate the emotional intensity score for.\n",
    "\n",
    "\tReturns:\n",
    "\t\tfloat: The emotional intensity score of the conversation.\n",
    "\t\"\"\"\n",
    "\n",
    "\tclassifications = calculate_emotional_scores(sentence)\n",
    "\n",
    "\treturn 1 - classifications['neutral']\n",
    "\n",
    "\n",
    "def set_overall_emotional_intensity_score(meeting_df: pd.DataFrame, sentences_df: pd.DataFrame) -> pd.DataFrame:\n",
    "\t\"\"\"\n",
    "\tCalculate the emotional intensity score of a conversation based on the emotional intensity of the sentences in the conversation.\n",
    "\n",
    "\tArgs:\n",
    "\t\tsentences_df (pd.DataFrame): The DataFrame containing the sentences to calculate the emotional intensity score for.\n",
    "\n",
    "\tReturns:\n",
    "\t\tpd.DataFrame: The DataFrame containing the emotional intensity scores of the sentences.\n",
    "\t\"\"\"\n",
    "\n",
    "\tsentences_df['emotional_intensity_score'] = sentences_df['text'].apply(calculate_emotional_intensity_score)\n",
    "\temotional_scores = sentences_df['text'].apply(calculate_emotional_scores).apply(pd.Series)\n",
    "\tfor emotion in emotions:\n",
    "\t\tsentences_df[emotion] = emotional_scores[emotion]\n",
    "\n",
    "\tsentences_df['duration'] = sentences_df['end_time'] - sentences_df['start_time']\n",
    "\n",
    "\t# Calculate the weighted emotional intensity score and weighted emotional scores\n",
    "\tsentences_df['weighted_emotional_intensity_score'] = sentences_df['emotional_intensity_score'] * sentences_df['duration']\n",
    "\tfor emotion in emotions:\n",
    "\t\tsentences_df[f'weighted_{emotion}'] = sentences_df[emotion] * sentences_df['duration']\n",
    "\t\n",
    "\toverall_emotional_intensity_score = sentences_df['weighted_emotional_intensity_score'].sum() / sentences_df['duration'].sum() if sentences_df['duration'].sum() != 0 else 0\n",
    "\tweighted_emotional_scores = {}\n",
    "\tfor emotion in emotions:\n",
    "\t\tweighted_emotional_scores[emotion] = sentences_df[f'weighted_{emotion}'].sum() / sentences_df['duration'].sum() if sentences_df['duration'].sum() != 0 else 0\n",
    "\n",
    "\tmeeting_df['emotional_intensity_score'] = overall_emotional_intensity_score\n",
    "\tfor emotion in emotions:\n",
    "\t\tmeeting_df[emotion] = weighted_emotional_scores[emotion]\n",
    "\n",
    "\treturn meeting_df, sentences_df\n",
    "\n",
    "\n",
    "meeting_df, sentences_df = set_overall_emotional_intensity_score(meeting_df, sentences_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Balance Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sentiment_balance_ratio(meeting_df: pd.DataFrame, sentences_df: pd.DataFrame) -> pd.DataFrame:\n",
    "\t\"\"\"\n",
    "\tCalculate the sentiment balance ratio of a conversation based on the sentiment of the sentences in the conversation.\n",
    "\n",
    "\tArgs:\n",
    "\t\tsentences_df (pd.DataFrame): The DataFrame containing the sentences to calculate the sentiment balance ratio for.\n",
    "\n",
    "\tReturns:\n",
    "\t\tpd.DataFrame: The DataFrame containing the sentiment balance ratio of the sentences.\n",
    "\t\"\"\"\n",
    "\n",
    "\t# If sentiment_score do not exist, calculate it\n",
    "\tif 'sentiment_score' not in meeting_df.columns:\n",
    "\t\tmeeting_df, sentences_df = set_overall_sentiment_score(meeting_df, sentences_df)\n",
    "\n",
    "\t# Classify the sentiment of each sentence\n",
    "\tsentences_df['sentiment'] = np.where(sentences_df['sentiment_score'] > 0, 'positive', np.where(sentences_df['sentiment_score'] < 0, 'negative', 'neutral'))\n",
    "\n",
    "\t# Calculate the sentiment balance ratio using log BSR\n",
    "\tsentiment_balance_ratio = np.log(((sentences_df['sentiment'] == 'positive').sum() + 0.000_000_1) / ((sentences_df['sentiment'] == 'negative').sum() + 0.000_000_1))\n",
    "\n",
    "\tmeeting_df['sentiment_balance_ratio'] = sentiment_balance_ratio\n",
    "\n",
    "\treturn meeting_df, sentences_df\n",
    "\n",
    "\n",
    "meeting_df, sentences_df = set_sentiment_balance_ratio(meeting_df, sentences_df)\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker Sentiment Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_speaker_sentiment_contribution(meeting_df: pd.DataFrame, sentences_df: pd.DataFrame) -> pd.DataFrame:\n",
    "\t\"\"\"\n",
    "\tCalculate the sentiment contribution of each speaker in a conversation based on the sentiment of the sentences spoken by each speaker.\n",
    "\n",
    "\tArgs:\n",
    "\t\tsentences_df (pd.DataFrame): The DataFrame containing the sentences to calculate the sentiment contribution for.\n",
    "\n",
    "\tReturns:\n",
    "\t\tpd.DataFrame: The DataFrame containing the sentiment contribution of each speaker.\n",
    "\t\"\"\"\n",
    "\n",
    "\t# If sentiment_score do not exist, calculate it\n",
    "\tif 'sentiment_score' not in meeting_df.columns:\n",
    "\t\tmeeting_df, sentences_df = set_overall_sentiment_score(meeting_df, sentences_df)\n",
    "\n",
    "\t# Calculate the sentiment contribution of each speaker\n",
    "\tsum_sentiment_scores = sentences_df.groupby('is_account_executive')['sentiment_score'].sum()\n",
    "\tduration_speaker_talks = sentences_df.groupby('is_account_executive')['duration'].sum()\n",
    "\n",
    "\tsentiment_contribution = (sum_sentiment_scores / duration_speaker_talks)\n",
    "\n",
    "\tmeeting_df['ae_sentiment'] = sentiment_contribution[True] if True in sentiment_contribution else 0\n",
    "\tmeeting_df['client_sentiment'] = sentiment_contribution[False] if False in sentiment_contribution else 0\n",
    "\n",
    "\treturn meeting_df, sentences_df\n",
    "\n",
    "\n",
    "meeting_df, sentences_df = set_speaker_sentiment_contribution(meeting_df, sentences_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sentiment Variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_speaker_sentiment_variability(meeting_df: pd.DataFrame, sentences_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the sentiment variability (weighted standard deviation) of each speaker in a conversation\n",
    "    based on the sentiment of the sentences spoken by each speaker.\n",
    "\n",
    "    Args:\n",
    "        meeting_df (pd.DataFrame): The DataFrame containing meeting-level data.\n",
    "        sentences_df (pd.DataFrame): The DataFrame containing sentence-level data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated meeting_df containing the sentiment variability of each speaker.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure 'sentiment_score' exists\n",
    "    if 'sentiment_score' not in sentences_df.columns:\n",
    "        meeting_df, sentences_df = set_overall_sentiment_score(meeting_df, sentences_df)\n",
    "\n",
    "    # Define a function to calculate weighted standard deviation\n",
    "    def weighted_std(values, weights):\n",
    "        \"\"\"\n",
    "        Return the weighted standard deviation.\n",
    "        values, weights -- Numpy arrays with the same shape.\n",
    "        \"\"\"\n",
    "        average = np.average(values, weights=weights)\n",
    "        variance = np.average((values - average)**2, weights=weights)\n",
    "        return np.sqrt(variance)\n",
    "\n",
    "    variability = {}\n",
    "    grouped = sentences_df.groupby('is_account_executive')\n",
    "\n",
    "\t# Get sentiment scores and durations\n",
    "    for is_ae, group in grouped:\n",
    "        sentiments = group['sentiment_score']\n",
    "        durations = group['duration']\n",
    "\n",
    "        if len(sentiments) > 1:\n",
    "            std = weighted_std(sentiments, durations)\n",
    "        else:\n",
    "            std = 0\n",
    "\n",
    "        variability[is_ae] = std\n",
    "\n",
    "    # Update meeting_df with the sentiment variability\n",
    "    meeting_df['ae_sentiment_variability'] = variability.get(True, 0)\n",
    "    meeting_df['client_sentiment_variability'] = variability.get(False, 0)\n",
    "\n",
    "    return meeting_df, sentences_df\n",
    "\n",
    "meeting_df, sentences_df = set_speaker_sentiment_variability(meeting_df, sentences_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_speaker_sentiment_trend(meeting_df: pd.DataFrame, sentences_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the sentiment trend (slope over time) of each speaker in a conversation\n",
    "    based on the sentiment of the sentences spoken by each speaker.\n",
    "\n",
    "    Args:\n",
    "        meeting_df (pd.DataFrame): The DataFrame containing meeting-level data.\n",
    "        sentences_df (pd.DataFrame): The DataFrame containing sentence-level data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated meeting_df containing the sentiment trend of each speaker.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure 'sentiment_score' exists\n",
    "    if 'sentiment_score' not in sentences_df.columns:\n",
    "        # Assuming set_overall_sentiment_score function exists and calculates sentiment scores\n",
    "        meeting_df, sentences_df = set_overall_sentiment_score(meeting_df, sentences_df)\n",
    "\n",
    "    # Ensure 'utterance_index' exists to represent the sequence of sentences\n",
    "    if 'utterance_index' not in sentences_df.columns:\n",
    "        # Assign a sequence number to each sentence in the order they appear\n",
    "        sentences_df = sentences_df.reset_index(drop=True)\n",
    "        sentences_df['utterance_index'] = sentences_df.index + 1  # Starts from 1\n",
    "\n",
    "    # Initialize dictionaries to store sentiment trends\n",
    "    sentiment_trend = {}\n",
    "\n",
    "    # Group by 'is_account_executive' to separate speakers\n",
    "    grouped = sentences_df.groupby('is_account_executive')\n",
    "\n",
    "    for is_ae, group in grouped:\n",
    "        # Get sentiment scores and utterance indices\n",
    "        sentiments = group['sentiment_score']\n",
    "        indices = group['utterance_index']\n",
    "\n",
    "        # Check if there are at least two points to calculate a trend\n",
    "        if len(sentiments) > 1:\n",
    "            # Perform linear regression\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(indices, sentiments)\n",
    "        else:\n",
    "            slope = 0  # If only one sentence, trend is zero\n",
    "\n",
    "        # Store the sentiment trend\n",
    "        sentiment_trend[is_ae] = slope\n",
    "\n",
    "    # Update meeting_df with the sentiment trends\n",
    "    meeting_df['ae_sentiment_trend'] = sentiment_trend.get(True, 0)\n",
    "    meeting_df['client_sentiment_trend'] = sentiment_trend.get(False, 0)\n",
    "\n",
    "    return meeting_df, sentences_df\n",
    "\n",
    "\n",
    "meeting_df, sentences_df = set_speaker_sentiment_trend(meeting_df, sentences_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotional Reciprocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_emotional_reciprocity(meeting_df: pd.DataFrame, sentences_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Emotional Reciprocity between the sales representative and the buyer\n",
    "    by computing the correlation between their sentiment scores over time.\n",
    "\n",
    "    Args:\n",
    "        meeting_df (pd.DataFrame): The DataFrame containing meeting-level data.\n",
    "        sentences_df (pd.DataFrame): The DataFrame containing sentence-level data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated meeting_df containing the Emotional Reciprocity metric.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure 'sentiment_score' exists\n",
    "    if 'sentiment_score' not in sentences_df.columns:\n",
    "        # Assuming set_overall_sentiment_score function exists and calculates sentiment scores\n",
    "        meeting_df, sentences_df = set_overall_sentiment_score(meeting_df, sentences_df)\n",
    "\n",
    "    # Ensure 'utterance_index' exists to represent the sequence of sentences\n",
    "    if 'utterance_index' not in sentences_df.columns:\n",
    "        # Assign a sequence number to each sentence in the order they appear\n",
    "        sentences_df = sentences_df.reset_index(drop=True)\n",
    "        sentences_df['utterance_index'] = sentences_df.index + 1  # Starts from 1\n",
    "\n",
    "    # Separate sentiments by speaker\n",
    "    ae_df = sentences_df[sentences_df['is_account_executive'] == True][['utterance_index', 'sentiment_score']]\n",
    "    client_df = sentences_df[sentences_df['is_account_executive'] == False][['utterance_index', 'sentiment_score']]\n",
    "\n",
    "    # Merge the two DataFrames on 'utterance_index' using forward and backward filling\n",
    "    merged_df = pd.merge_asof(\n",
    "        client_df.sort_values('utterance_index'),\n",
    "        ae_df.sort_values('utterance_index'),\n",
    "        on='utterance_index',\n",
    "        direction='nearest',\n",
    "        suffixes=('_client', '_ae')\n",
    "    )\n",
    "\n",
    "    # Drop rows with missing values (if any)\n",
    "    merged_df = merged_df.dropna(subset=['sentiment_score_ae', 'sentiment_score_client'])\n",
    "\n",
    "    # Check if there are at least two data points to calculate correlation\n",
    "    if len(merged_df) >= 2:\n",
    "        # Calculate Pearson correlation coefficient\n",
    "        corr_coef, p_value = pearsonr(merged_df['sentiment_score_ae'], merged_df['sentiment_score_client'])\n",
    "        emotional_reciprocity = corr_coef\n",
    "    else:\n",
    "        emotional_reciprocity = 0  # Not enough data to calculate correlation\n",
    "\n",
    "    # Update meeting_df with Emotional Reciprocity\n",
    "    meeting_df['emotional_reciprocity'] = emotional_reciprocity\n",
    "\n",
    "    return meeting_df, sentences_df\n",
    "\n",
    "\n",
    "meeting_df, sentences_df = set_emotional_reciprocity(meeting_df, sentences_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>ae_name</th>\n",
       "      <th>ae_email</th>\n",
       "      <th>sales_outcome</th>\n",
       "      <th>date</th>\n",
       "      <th>meeting_attendees</th>\n",
       "      <th>host_email</th>\n",
       "      <th>transcript_url</th>\n",
       "      <th>video_url</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sentiment_balance_ratio</th>\n",
       "      <th>ae_sentiment</th>\n",
       "      <th>client_sentiment</th>\n",
       "      <th>ae_sentiment_variability</th>\n",
       "      <th>client_sentiment_variability</th>\n",
       "      <th>ae_sentiment_trend</th>\n",
       "      <th>client_sentiment_trend</th>\n",
       "      <th>emotional_reciprocity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jKr7GjngjZdqWWiW</td>\n",
       "      <td>Conchita &lt;&gt; My Amazon Guy</td>\n",
       "      <td>Matt Lopez</td>\n",
       "      <td>matt.lopez@myamazonguy.com</td>\n",
       "      <td>None</td>\n",
       "      <td>2024/04/04</td>\n",
       "      <td>matt.lopez@myamazonguy.com, info@nefertitisecr...</td>\n",
       "      <td>neslie.bartoline@myamazonguy.com</td>\n",
       "      <td>https://app.fireflies.ai/view/jKr7GjngjZdqWWiW</td>\n",
       "      <td>https://cdn.fireflies.ai/jKr7GjngjZdqWWiW/vide...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.998529</td>\n",
       "      <td>0.094592</td>\n",
       "      <td>0.024425</td>\n",
       "      <td>0.394221</td>\n",
       "      <td>0.440253</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>0.182185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                      title     ae_name  \\\n",
       "0  jKr7GjngjZdqWWiW  Conchita <> My Amazon Guy  Matt Lopez   \n",
       "\n",
       "                     ae_email sales_outcome        date  \\\n",
       "0  matt.lopez@myamazonguy.com          None  2024/04/04   \n",
       "\n",
       "                                   meeting_attendees  \\\n",
       "0  matt.lopez@myamazonguy.com, info@nefertitisecr...   \n",
       "\n",
       "                         host_email  \\\n",
       "0  neslie.bartoline@myamazonguy.com   \n",
       "\n",
       "                                   transcript_url  \\\n",
       "0  https://app.fireflies.ai/view/jKr7GjngjZdqWWiW   \n",
       "\n",
       "                                           video_url  ...   sadness  surprise  \\\n",
       "0  https://cdn.fireflies.ai/jKr7GjngjZdqWWiW/vide...  ...  0.023438    0.0884   \n",
       "\n",
       "   sentiment_balance_ratio  ae_sentiment  client_sentiment  \\\n",
       "0                 0.998529      0.094592          0.024425   \n",
       "\n",
       "   ae_sentiment_variability  client_sentiment_variability  ae_sentiment_trend  \\\n",
       "0                  0.394221                      0.440253           -0.000074   \n",
       "\n",
       "   client_sentiment_trend  emotional_reciprocity  \n",
       "0               -0.000143               0.182185  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meeting_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>text</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>task</th>\n",
       "      <th>pricing</th>\n",
       "      <th>metric</th>\n",
       "      <th>question</th>\n",
       "      <th>date_and_time</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>weighted_emotional_intensity_score</th>\n",
       "      <th>weighted_anger</th>\n",
       "      <th>weighted_disgust</th>\n",
       "      <th>weighted_fear</th>\n",
       "      <th>weighted_joy</th>\n",
       "      <th>weighted_sadness</th>\n",
       "      <th>weighted_surprise</th>\n",
       "      <th>utterance_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matthew Lopez</td>\n",
       "      <td>0</td>\n",
       "      <td>It.</td>\n",
       "      <td>25.634</td>\n",
       "      <td>26.174</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023097</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>0.061940</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>0.018391</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.012472</td>\n",
       "      <td>0.014868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matthew Lopez</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey there.</td>\n",
       "      <td>573.254</td>\n",
       "      <td>573.686</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024065</td>\n",
       "      <td>0.070499</td>\n",
       "      <td>0.227579</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.166911</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>0.030455</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matthew Lopez</td>\n",
       "      <td>0</td>\n",
       "      <td>How are you?</td>\n",
       "      <td>573.710</td>\n",
       "      <td>574.558</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>How are you?</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023498</td>\n",
       "      <td>0.685494</td>\n",
       "      <td>0.691516</td>\n",
       "      <td>0.053873</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.024517</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.019926</td>\n",
       "      <td>0.581299</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEFERTITI SECRETS</td>\n",
       "      <td>1</td>\n",
       "      <td>Hello, how are you?</td>\n",
       "      <td>574.726</td>\n",
       "      <td>576.446</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Hello, how are you?</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.610221</td>\n",
       "      <td>0.024342</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.025725</td>\n",
       "      <td>0.023240</td>\n",
       "      <td>0.016714</td>\n",
       "      <td>0.513433</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEFERTITI SECRETS</td>\n",
       "      <td>1</td>\n",
       "      <td>Good afternoon.</td>\n",
       "      <td>576.470</td>\n",
       "      <td>577.518</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014931</td>\n",
       "      <td>0.011890</td>\n",
       "      <td>0.320857</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.282726</td>\n",
       "      <td>0.015648</td>\n",
       "      <td>0.012461</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker_name  speaker_id                 text  start_time  end_time  \\\n",
       "0      Matthew Lopez           0                  It.      25.634    26.174   \n",
       "1      Matthew Lopez           0           Hey there.     573.254   573.686   \n",
       "2      Matthew Lopez           0         How are you?     573.710   574.558   \n",
       "3  NEFERTITI SECRETS           1  Hello, how are you?     574.726   576.446   \n",
       "4  NEFERTITI SECRETS           1      Good afternoon.     576.470   577.518   \n",
       "\n",
       "   task pricing metric             question date_and_time  ...   sadness  \\\n",
       "0  None    None   None                 None          None  ...  0.023097   \n",
       "1  None    None   None                 None          None  ...  0.024065   \n",
       "2  None    None   None         How are you?          None  ...  0.023498   \n",
       "3  None    None   None  Hello, how are you?          None  ...  0.009718   \n",
       "4  None    None   None                 None          None  ...  0.014931   \n",
       "\n",
       "   surprise  weighted_emotional_intensity_score  weighted_anger  \\\n",
       "0  0.027533                            0.061940        0.008602   \n",
       "1  0.070499                            0.227579        0.010572   \n",
       "2  0.685494                            0.691516        0.053873   \n",
       "3  0.298507                            0.610221        0.024342   \n",
       "4  0.011890                            0.320857        0.003236   \n",
       "\n",
       "   weighted_disgust  weighted_fear  weighted_joy  weighted_sadness  \\\n",
       "0          0.018391       0.004778      0.002828          0.012472   \n",
       "1          0.007491       0.001754      0.166911          0.010396   \n",
       "2          0.008301       0.024517      0.003600          0.019926   \n",
       "3          0.006767       0.025725      0.023240          0.016714   \n",
       "4          0.005225       0.001562      0.282726          0.015648   \n",
       "\n",
       "   weighted_surprise  utterance_index  \n",
       "0           0.014868                1  \n",
       "1           0.030455                2  \n",
       "2           0.581299                3  \n",
       "3           0.513433                4  \n",
       "4           0.012461                5  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
